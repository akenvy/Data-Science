{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwO1SLBD5gAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_cIai3p6xYY",
        "colab_type": "code",
        "outputId": "bf6a7790-b3b0-42bc-e03c-0e587e9ae6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX_5eKFyPMdF",
        "colab_type": "code",
        "outputId": "e0758eb1-1a5b-4fac-b289-9af60eecf647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNq8BQe0_6fi",
        "colab_type": "code",
        "outputId": "82d0a0fc-e63d-4faa-de25-524660816fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".  ..  .config\t.kaggle  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Stw8MNAKkP",
        "colab_type": "code",
        "outputId": "46fbb229-f55c-4c41-a650-1ebcf1e0e9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SAiYO_RAVem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"envykhamidov\",\"key\":\"fdd2921f97a333303ae41722b3421d9f\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB6AgCRNBOBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVar6-RaJN5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrBFmpf9CEZg",
        "colab_type": "code",
        "outputId": "2ea36431-2a67-4ab0-b093-1fa4b319cc4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyqPaON9Jqv0",
        "colab_type": "code",
        "outputId": "12d6c2f0-b8a5-4ad6-a013-cc8adbbac0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "!kaggle competitions download -c chinese-char-recognition-smmo19"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train-2.npy.zip to {/content}/competitions/chinese-char-recognition-smmo19\n",
            " 88% 145M/165M [00:01<00:00, 106MB/s] \n",
            "100% 165M/165M [00:01<00:00, 132MB/s]\n",
            "Downloading train-3.npy.zip to {/content}/competitions/chinese-char-recognition-smmo19\n",
            " 91% 169M/185M [00:02<00:00, 60.4MB/s]\n",
            "100% 185M/185M [00:02<00:00, 80.3MB/s]\n",
            "Downloading train-4.npy.zip to {/content}/competitions/chinese-char-recognition-smmo19\n",
            " 87% 169M/195M [00:02<00:00, 71.3MB/s]\n",
            "100% 195M/195M [00:02<00:00, 94.2MB/s]\n",
            "Downloading test.npy.zip to {/content}/competitions/chinese-char-recognition-smmo19\n",
            " 96% 193M/202M [00:01<00:00, 118MB/s]\n",
            "100% 202M/202M [00:01<00:00, 120MB/s]\n",
            "Downloading train-1.npy.zip to {/content}/competitions/chinese-char-recognition-smmo19\n",
            " 80% 90.0M/113M [00:00<00:00, 53.5MB/s]\n",
            "100% 113M/113M [00:00<00:00, 122MB/s]  \n",
            "Downloading random_labels.csv to {/content}/competitions/chinese-char-recognition-smmo19\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 136MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDzrkb1rJ_3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1 = zipfile.ZipFile('/content/{/content}/competitions/chinese-char-recognition-smmo19/test.npy.zip', 'r')\n",
        "a2 = zipfile.ZipFile('/content/{/content}/competitions/chinese-char-recognition-smmo19/train-1.npy.zip', 'r')\n",
        "a3 = zipfile.ZipFile('/content/{/content}/competitions/chinese-char-recognition-smmo19/train-2.npy.zip', 'r')\n",
        "a4 = zipfile.ZipFile('/content/{/content}/competitions/chinese-char-recognition-smmo19/train-3.npy.zip', 'r')\n",
        "a5 = zipfile.ZipFile('/content/{/content}/competitions/chinese-char-recognition-smmo19/train-4.npy.zip', 'r')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pRDzH4KN_Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1.extractall()\n",
        "a2.extractall()\n",
        "a3.extractall()\n",
        "a4.extractall()\n",
        "a5.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhFhtlr55pVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = np.load(\"./train-1.npy\", allow_pickle=True)\n",
        "for i in range(2, 5):\n",
        "    t = np.load(f\"./train-{i}.npy\", allow_pickle=True)\n",
        "    data_train = np.concatenate([data_train, t])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaLlvvrcEE2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = np.load(\"./test.npy\", allow_pickle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4_0U1ezBmLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.arange(0,1000)\n",
        "b = np.unique(data_train[:, 1])\n",
        "#for i in range(len(data_train[:, 1])):\n",
        " # for j in range(len(b)):\n",
        "  #  if data_train[i, 1] == b[j]:\n",
        "     # data_train[i , 1] = a[j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAAqzvDfW-Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slovar = {}\n",
        "temp = np.eye(1000)\n",
        "for i in range(len(b)):\n",
        "  slovar[b[i]] = temp[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGYYhNm1hIc_",
        "colab_type": "code",
        "outputId": "4829d423-45a9-443a-ca81-4c62cdfd528e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(data_train[:, 0], data_train[:, 1], test_size=0.1, random_state=42)\n",
        "X_train = X_train_.reshape(-1, 1) \n",
        "X_test  = X_test_.reshape(-1, 1)  \n",
        "y_train = y_train_.reshape(-1, 1)  \n",
        "y_test  = y_test_.reshape(-1, 1) \n",
        "raw_train = np.concatenate([X_train, y_train], axis = 1)\n",
        "raw_test = np.concatenate([X_test, y_test], axis = 1)\n",
        "raw_train.shape, raw_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((299688, 2), (33299, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0v1LN7YJRKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tf.compat.v1.disable_tensor_equality()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-TS-J_SfQwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 64\n",
        "def preprocess_train(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / 127.5) - 1\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))  \n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okn_2l4gEie1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "def train_gen():\n",
        "    for img, label in raw_train:\n",
        "        img = img[..., None] # [batch, w, h, channels]\n",
        "        yield img, slovar[label]\n",
        "\n",
        "ds_train = tf.data.Dataset.from_generator(train_gen,\n",
        "                                          output_types=(tf.float32, tf.int32),\n",
        "                                          output_shapes=((None,None,1), (1000))\n",
        "                                         ).map(preprocess_train, num_parallel_calls=-1).prefetch(-1).shuffle(1024).batch(batch_size).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax2C0LaBIahn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "def train_gen1():\n",
        "    for img, label in data_train:\n",
        "        img = img[..., None] # [batch, w, h, channels]\n",
        "        yield img, slovar[label]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(train_gen1,\n",
        "                                          output_types=(tf.float32, tf.int32),\n",
        "                                          output_shapes=((None,None,1), (1000))\n",
        "                                         ).map(preprocess_train, num_parallel_calls=-1).prefetch(-1).shuffle(1024).batch(batch_size).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j-OzfHIGWWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gen2():\n",
        "    for img, label in raw_test:\n",
        "        img = img[..., None] # [batch, w, h, channels]\n",
        "        yield img, slovar[label]\n",
        "\n",
        "ds_test = tf.data.Dataset.from_generator(train_gen2,\n",
        "                                          output_types=(tf.float32, tf.int32),\n",
        "                                          output_shapes=((None,None,1), (1000))\n",
        "                                         ).map(preprocess_train, num_parallel_calls=-1).prefetch(-1).shuffle(1024).batch(batch_size).repeat()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKQnvCmxdaEU",
        "colab_type": "code",
        "outputId": "efecbfdf-2127-4b21-c1a9-ed3ce2a03145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import load_model"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jKHvZ_izoNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import initializers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ettqmCP7l8F",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "tf.keras.layers.Conv2D(filters=16, padding='same', kernel_size=(3,3), input_shape=(64,64, 1),\n",
        "activation='relu', kernel_initializer = 'glorot_normal'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=(3,3), \n",
        "activation='relu', kernel_initializer = 'glorot_normal'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=64, padding='same', kernel_size=(3,3),\n",
        "activation='relu', kernel_initializer = 'glorot_normal'),\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
        "\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=64, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=128, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
        "\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=64, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=128, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=256, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
        "\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=256, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=512, padding='same', kernel_size=(3,3), kernel_initializer='glorot_normal',\n",
        "activation='relu'),\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
        "\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "tf.keras.layers.Flatten(),\n",
        "\n",
        "tf.keras.layers.Dense(4096, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "tf.keras.layers.Dense(2048, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "tf.keras.layers.Dense(1000, activation = 'softmax')])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8aKsYZFP3nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMYB6RKuGc_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "       self.losses = []\n",
        "       self.lr = []\n",
        " \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "       self.losses.append(logs.get('loss'))\n",
        "       self.lr.append(step_decay(len(self.losses)))\n",
        "       print(\"\\n\", ' lr:', step_decay(len(self.losses)))\n",
        "\n",
        "\n",
        "def step_decay(epoch):\n",
        "   initial_lrate = 0.0005\n",
        "   lrate = initial_lrate * 0.9 ** epoch\n",
        "   return lrate\n",
        "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "\n",
        "loss_history = LossHistory()\n",
        "callbacks_list = [loss_history, lrate]\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJUuyyH2GSkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5WdH6gWGa-1",
        "colab_type": "code",
        "outputId": "2255adb2-305a-47a4-9733-197dd45985d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(ds_train, steps_per_epoch= 1000,\n",
        "           epochs=60, shuffle=True, validation_data = ds_test, validation_steps = 1000, use_multiprocessing = True,\n",
        "         verbose = 1, callbacks = [loss_history, lrate])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1000 steps, validate for 1000 steps\n",
            "Epoch 1/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 6.7299 - accuracy: 0.0039\n",
            "  lr: 0.00045000000000000004\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 6.7297 - accuracy: 0.0040 - val_loss: 6.1214 - val_accuracy: 0.0090\n",
            "Epoch 2/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 5.3575 - accuracy: 0.0422\n",
            "  lr: 0.00040500000000000003\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 5.3568 - accuracy: 0.0422 - val_loss: 3.9270 - val_accuracy: 0.1574\n",
            "Epoch 3/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 3.1299 - accuracy: 0.2832\n",
            "  lr: 0.0003645000000000001\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 3.1276 - accuracy: 0.2836 - val_loss: 1.8129 - val_accuracy: 0.5415\n",
            "Epoch 4/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.4972 - accuracy: 0.6109\n",
            "  lr: 0.00032805000000000003\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 1.4963 - accuracy: 0.6112 - val_loss: 0.7252 - val_accuracy: 0.8262\n",
            "Epoch 5/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.9272 - accuracy: 0.7527\n",
            "  lr: 0.000295245\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.9263 - accuracy: 0.7528 - val_loss: 0.3858 - val_accuracy: 0.8932\n",
            "Epoch 6/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.8229\n",
            "  lr: 0.0002657205\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6506 - accuracy: 0.8229 - val_loss: 0.2910 - val_accuracy: 0.9210\n",
            "Epoch 7/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.8613\n",
            "  lr: 0.00023914845000000005\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.4993 - accuracy: 0.8614 - val_loss: 0.2355 - val_accuracy: 0.9358\n",
            "Epoch 8/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.4224 - accuracy: 0.8845\n",
            "  lr: 0.00021523360500000005\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.4223 - accuracy: 0.8845 - val_loss: 0.1844 - val_accuracy: 0.9504\n",
            "Epoch 9/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.3490 - accuracy: 0.9017\n",
            "  lr: 0.00019371024450000004\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.3493 - accuracy: 0.9018 - val_loss: 0.1578 - val_accuracy: 0.9571\n",
            "Epoch 10/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.9183\n",
            "  lr: 0.00017433922005000006\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2938 - accuracy: 0.9183 - val_loss: 0.1330 - val_accuracy: 0.9644\n",
            "Epoch 11/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9271\n",
            "  lr: 0.00015690529804500005\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2673 - accuracy: 0.9272 - val_loss: 0.1159 - val_accuracy: 0.9697\n",
            "Epoch 12/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.9340\n",
            "  lr: 0.00014121476824050004\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2382 - accuracy: 0.9340 - val_loss: 0.1039 - val_accuracy: 0.9724\n",
            "Epoch 13/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9450\n",
            "  lr: 0.00012709329141645005\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1929 - accuracy: 0.9450 - val_loss: 0.0899 - val_accuracy: 0.9759\n",
            "Epoch 14/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9506\n",
            "  lr: 0.00011438396227480505\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1728 - accuracy: 0.9506 - val_loss: 0.0841 - val_accuracy: 0.9780\n",
            "Epoch 15/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9591\n",
            "  lr: 0.00010294556604732454\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1438 - accuracy: 0.9591 - val_loss: 0.0790 - val_accuracy: 0.9790\n",
            "Epoch 16/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9635\n",
            "  lr: 9.265100944259208e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1274 - accuracy: 0.9635 - val_loss: 0.0730 - val_accuracy: 0.9810\n",
            "Epoch 17/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9661\n",
            "  lr: 8.338590849833288e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1193 - accuracy: 0.9662 - val_loss: 0.0694 - val_accuracy: 0.9821\n",
            "Epoch 18/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9692\n",
            "  lr: 7.504731764849959e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1058 - accuracy: 0.9692 - val_loss: 0.0615 - val_accuracy: 0.9846\n",
            "Epoch 19/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9736\n",
            "  lr: 6.754258588364964e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0904 - accuracy: 0.9736 - val_loss: 0.0609 - val_accuracy: 0.9853\n",
            "Epoch 20/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9731\n",
            "  lr: 6.078832729528467e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0933 - accuracy: 0.9732 - val_loss: 0.0546 - val_accuracy: 0.9867\n",
            "Epoch 21/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9756\n",
            "  lr: 5.470949456575621e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0852 - accuracy: 0.9755 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
            "Epoch 22/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9787\n",
            "  lr: 4.923854510918059e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0741 - accuracy: 0.9787 - val_loss: 0.0508 - val_accuracy: 0.9883\n",
            "Epoch 23/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9786\n",
            "  lr: 4.431469059826253e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0729 - accuracy: 0.9785 - val_loss: 0.0479 - val_accuracy: 0.9891\n",
            "Epoch 24/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9821\n",
            "  lr: 3.988322153843628e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0619 - accuracy: 0.9822 - val_loss: 0.0464 - val_accuracy: 0.9887\n",
            "Epoch 25/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9834\n",
            "  lr: 3.589489938459265e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.0461 - val_accuracy: 0.9895\n",
            "Epoch 26/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9846\n",
            "  lr: 3.230540944613339e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0499 - accuracy: 0.9846 - val_loss: 0.0441 - val_accuracy: 0.9903\n",
            "Epoch 27/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9864\n",
            "  lr: 2.9074868501520047e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0472 - accuracy: 0.9864 - val_loss: 0.0427 - val_accuracy: 0.9908\n",
            "Epoch 28/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9861\n",
            "  lr: 2.6167381651368046e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0465 - accuracy: 0.9860 - val_loss: 0.0437 - val_accuracy: 0.9908\n",
            "Epoch 29/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9869\n",
            "  lr: 2.3550643486231242e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 0.0412 - val_accuracy: 0.9910\n",
            "Epoch 30/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9877\n",
            "  lr: 2.119557913760812e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 0.0406 - val_accuracy: 0.9910\n",
            "Epoch 31/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9875\n",
            "  lr: 1.9076021223847307e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0402 - val_accuracy: 0.9912\n",
            "Epoch 32/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9877\n",
            "  lr: 1.7168419101462575e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0400 - val_accuracy: 0.9912\n",
            "Epoch 33/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9882\n",
            "  lr: 1.545157719131632e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0388 - val_accuracy: 0.9913\n",
            "Epoch 34/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9898\n",
            "  lr: 1.3906419472184688e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0385 - val_accuracy: 0.9915\n",
            "Epoch 35/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9912\n",
            "  lr: 1.2515777524966218e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0390 - val_accuracy: 0.9918\n",
            "Epoch 36/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9910\n",
            "  lr: 1.1264199772469598e-05\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.0387 - val_accuracy: 0.9921\n",
            "Epoch 37/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9911\n",
            "  lr: 1.0137779795222638e-05\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0385 - val_accuracy: 0.9920\n",
            "Epoch 38/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9906\n",
            "  lr: 9.124001815700376e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.0384 - val_accuracy: 0.9916\n",
            "Epoch 39/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9906\n",
            "  lr: 8.211601634130337e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.0378 - val_accuracy: 0.9919\n",
            "Epoch 40/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9908\n",
            "  lr: 7.390441470717304e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0372 - val_accuracy: 0.9921\n",
            "Epoch 41/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9914\n",
            "  lr: 6.651397323645573e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
            "Epoch 42/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9908\n",
            "  lr: 5.9862575912810165e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0376 - val_accuracy: 0.9920\n",
            "Epoch 43/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9905\n",
            "  lr: 5.387631832152915e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
            "Epoch 44/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9921\n",
            "  lr: 4.848868648937623e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0374 - val_accuracy: 0.9922\n",
            "Epoch 45/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9922\n",
            "  lr: 4.363981784043861e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0376 - val_accuracy: 0.9919\n",
            "Epoch 46/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9918\n",
            "  lr: 3.927583605639475e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0376 - val_accuracy: 0.9921\n",
            "Epoch 47/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9922\n",
            "  lr: 3.534825245075528e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0372 - val_accuracy: 0.9921\n",
            "Epoch 48/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9917\n",
            "  lr: 3.181342720567975e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0372 - val_accuracy: 0.9921\n",
            "Epoch 49/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9922\n",
            "  lr: 2.8632084485111773e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.0374 - val_accuracy: 0.9922\n",
            "Epoch 50/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9915\n",
            "  lr: 2.57688760366006e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
            "Epoch 51/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9918\n",
            "  lr: 2.319198843294054e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0371 - val_accuracy: 0.9923\n",
            "Epoch 52/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9922\n",
            "  lr: 2.0872789589646486e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.0369 - val_accuracy: 0.9923\n",
            "Epoch 53/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9927\n",
            "  lr: 1.8785510630681838e-06\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0376 - val_accuracy: 0.9923\n",
            "Epoch 54/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9927\n",
            "  lr: 1.6906959567613654e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0380 - val_accuracy: 0.9923\n",
            "Epoch 55/60\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9921\n",
            "  lr: 1.5216263610852289e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.0369 - val_accuracy: 0.9924\n",
            "Epoch 56/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9930\n",
            "  lr: 1.3694637249767062e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0367 - val_accuracy: 0.9923\n",
            "Epoch 57/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9922\n",
            "  lr: 1.2325173524790356e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0368 - val_accuracy: 0.9923\n",
            "Epoch 58/60\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
            "  lr: 1.109265617231132e-06\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0373 - val_accuracy: 0.9923\n",
            "Epoch 59/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9932\n",
            "  lr: 9.983390555080187e-07\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.0369 - val_accuracy: 0.9924\n",
            "Epoch 60/60\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9930\n",
            "  lr: 8.98505149957217e-07\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0370 - val_accuracy: 0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4860ab7dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r0lJb31Ih8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_train1(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / 127.5) - 1\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))  \n",
        "    return image\n",
        "\n",
        "def train_gen3():\n",
        "    for img in data_test:\n",
        "        img = img[..., None] # [batch, w, h, channels]\n",
        "        yield img\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(train_gen3,\n",
        "                                          output_types=(tf.float32),\n",
        "                                          output_shapes=((None,None,1)\n",
        "                                         )).map(preprocess_train1, num_parallel_calls=-1).prefetch(-1).batch(batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cBXCHxgOniF",
        "colab_type": "code",
        "outputId": "c2567a16-c0a6-499b-dfbe-556e8952d8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "preds = model.predict(test_dataset, verbose = 1)\n",
        "preds"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2602/2602 [==============================] - 29s 11ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.9500943e-29, 5.4592164e-27, 2.2573682e-26, ..., 2.4409804e-28,\n",
              "        1.7933741e-30, 1.0734788e-21],\n",
              "       [2.9998174e-22, 4.1382201e-26, 2.9018090e-27, ..., 9.3723807e-18,\n",
              "        1.9840636e-18, 4.4558329e-18],\n",
              "       [5.5996799e-23, 2.8356441e-33, 7.5742780e-21, ..., 3.5577068e-36,\n",
              "        1.1240191e-34, 1.3059117e-33],\n",
              "       ...,\n",
              "       [5.1629688e-19, 9.4464582e-11, 1.6449226e-20, ..., 1.7336350e-15,\n",
              "        1.5423432e-13, 2.2155753e-17],\n",
              "       [3.9959623e-30, 9.5887381e-23, 7.4763762e-32, ..., 2.0597079e-16,\n",
              "        1.5227912e-20, 5.8867466e-18],\n",
              "       [1.3883081e-23, 5.2377914e-19, 3.9297762e-23, ..., 9.3265127e-12,\n",
              "        5.7775756e-10, 1.0420235e-13]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTJeSPwWOJ7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = np.arange(0,1000)\n",
        "slovar1 = {}\n",
        "for i in range(1000):\n",
        "  slovar1[c[i]] = b[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV2KpXWAZRes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = []\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "for i in predictions:\n",
        "  j.append(slovar1[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX7rCxnuapTJ",
        "colab_type": "code",
        "outputId": "2787692c-7614-40ef-8521-6d6236f0b5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "itog_pred = np.concatenate([np.arange(1, 83248).reshape(-1,1), np.array(j).reshape(-1,1)], axis = 1)\n",
        "itog_pred.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83247, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE2kQXrMNfdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('kaggle18.csv', itog_pred, delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXuwzrSxC5yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}